version: '3.9'

services:
  rag_server:
    build:
      context: ./RAG
      dockerfile: Dockerfile.rag
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "8000:8000"
    depends_on:
      - ollama
    volumes:
      - ./RAG:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 10

  rasa_server:
    build:
      context: ./RASA
      dockerfile: Dockerfile.rasa
    ports:
      - "5005:5005"
    volumes:
      - ./RASA:/app
    depends_on:
      - rasa_actions
    command: rasa run --enable-api --cors "*" --debug

  rasa_actions:
    build:
      context: ./RASA
      dockerfile: Dockerfile.actions
    ports:
      - "5055:5055"
    volumes:
      - ./RASA/actions:/app/actions

  client:
    build: 
      context: ./client
      dockerfile: Dockerfile.client
    ports:
      - "8080:80"
    depends_on:
      rag_server:
        condition: service_healthy

  
  ollama:
    image: ollama/ollama
    container_name: ollama
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "11434:11434"  # Ollama API port
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    command: serve
  
volumes:
  ollama_data: